{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d46b527-7854-45b5-b7cb-a90624840cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading classification data...\n",
      "INFO:__main__:Loading training dataset...\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 5415/5415 [00:01<00:00, 5074.99it/s]\n",
      "INFO:__main__:Loading test usernames...\n",
      "INFO:__main__:Loading regression test data...\n",
      "INFO:__main__:Starting classification...\n",
      "INFO:__main__:Processing profile data...\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5415/5415 [00:00<00:00, 833473.62it/s]\n",
      "INFO:__main__:Training classification model...\n",
      "INFO:__main__:Starting regression...\n",
      "INFO:__main__:Extracting posts data...\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5415/5415 [00:00<00:00, 251906.66it/s]\n",
      "INFO:__main__:Preparing regression features...\n",
      "INFO:__main__:Preparing regression features...\n",
      "INFO:__main__:Completed both classification and regression predictions!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    try:\n",
    "        # Load training classification data\n",
    "        logger.info(\"Loading classification data...\")\n",
    "        classification_data = pd.read_csv(\n",
    "            r'C:\\Users\\sarp2\\Desktop\\train-classification.csv', \n",
    "            delimiter=',', \n",
    "            header=None, \n",
    "            names=['username', 'label']\n",
    "        )\n",
    "\n",
    "        # Load training dataset\n",
    "        logger.info(\"Loading training dataset...\")\n",
    "        with open(r'C:/Users/sarp2/Desktop/training-dataset.jsonl', 'r', encoding='utf-8') as f:\n",
    "            training_data = [json.loads(line) for line in tqdm(f.readlines())]\n",
    "\n",
    "        # Load test usernames\n",
    "        logger.info(\"Loading test usernames...\")\n",
    "        with open(r'C:\\Users\\sarp2\\Desktop\\test-classification-round2.dat', 'r', encoding='utf-8') as f:\n",
    "            test_usernames = [line.strip().lower() for line in f.readlines()]\n",
    "\n",
    "        # Load regression test data\n",
    "        logger.info(\"Loading regression test data...\")\n",
    "        with open(r'C:\\Users\\sarp2\\Desktop\\test-regression-round2.jsonl', 'r', encoding='utf-8') as f:\n",
    "            regression_test_data = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "        return classification_data, training_data, test_usernames, regression_test_data\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def process_profile_data(training_data):\n",
    "    logger.info(\"Processing profile data...\")\n",
    "    flattened_data = []\n",
    "    \n",
    "    for record in tqdm(training_data):\n",
    "        if 'profile' in record:\n",
    "            profile = record['profile']\n",
    "            flattened_record = {\n",
    "                'username': profile.get('username', '').strip().lower(),\n",
    "                'follower_count': profile.get('follower_count', 0),\n",
    "                'following_count': profile.get('following_count', 0),\n",
    "                'post_count': profile.get('post_count', 0),\n",
    "                'is_private': profile.get('is_private', False),\n",
    "                'is_business_account': profile.get('is_business_account', False),\n",
    "                'is_verified': profile.get('is_verified', False)\n",
    "            }\n",
    "            flattened_data.append(flattened_record)\n",
    "    \n",
    "    return pd.DataFrame(flattened_data)\n",
    "\n",
    "def extract_posts_data(training_data):\n",
    "    logger.info(\"Extracting posts data...\")\n",
    "    all_posts = []\n",
    "    \n",
    "    for user_data in tqdm(training_data):\n",
    "        if 'posts' in user_data and isinstance(user_data['posts'], list):\n",
    "            for post in user_data['posts']:\n",
    "                if 'like_count' in post and post['like_count'] is not None:\n",
    "                    all_posts.append(post)\n",
    "    \n",
    "    return all_posts\n",
    "\n",
    "def prepare_regression_features(posts, tfidf=None, is_training=True):\n",
    "    logger.info(\"Preparing regression features...\")\n",
    "    \n",
    "    # Create DataFrame with basic features\n",
    "    features_df = pd.DataFrame([{\n",
    "        'caption': str(post.get('caption', '')),\n",
    "        'media_type': post.get('media_type', ''),\n",
    "        'comments_count': float(post.get('comments_count', 0)),\n",
    "    } for post in posts])\n",
    "\n",
    "    # Handle missing values\n",
    "    features_df['caption'] = features_df['caption'].fillna('')\n",
    "    features_df['media_type'] = features_df['media_type'].fillna('unknown')\n",
    "    features_df['comments_count'] = features_df['comments_count'].fillna(0)\n",
    "\n",
    "    # Create TF-IDF features\n",
    "    if tfidf is None and is_training:\n",
    "        tfidf = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "        tfidf_features = tfidf.fit_transform(features_df['caption'])\n",
    "    else:\n",
    "        tfidf_features = tfidf.transform(features_df['caption'])\n",
    "\n",
    "    # One-hot encode media_type\n",
    "    media_type_dummies = pd.get_dummies(features_df['media_type'], prefix='media_type')\n",
    "    \n",
    "    # Combine all features\n",
    "    final_features = pd.concat([\n",
    "        features_df[['comments_count']],\n",
    "        pd.DataFrame(tfidf_features.toarray()),\n",
    "        media_type_dummies\n",
    "    ], axis=1)\n",
    "\n",
    "    # Convert all column names to strings\n",
    "    final_features.columns = final_features.columns.astype(str)\n",
    "\n",
    "    if is_training:\n",
    "        return final_features, [float(post['like_count']) for post in posts], tfidf\n",
    "    return final_features, tfidf\n",
    "\n",
    "def train_classification_model(training_df, classification_data):\n",
    "    logger.info(\"Training classification model...\")\n",
    "    \n",
    "    # Normalize username fields\n",
    "    classification_data['username'] = classification_data['username'].str.strip().str.lower()\n",
    "\n",
    "    # Merge classification data with training data\n",
    "    merged_data = pd.merge(\n",
    "        training_df,\n",
    "        classification_data,\n",
    "        on='username',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    if merged_data.empty:\n",
    "        logger.warning(\"No matching usernames found between training data and classification data.\")\n",
    "        return None, None\n",
    "\n",
    "    # Extract features and labels\n",
    "    feature_columns = ['follower_count', 'following_count', 'post_count', \n",
    "                      'is_private', 'is_business_account', 'is_verified']\n",
    "    classification_features = merged_data[feature_columns]\n",
    "    classification_labels = merged_data['label']\n",
    "\n",
    "    # Label encoding\n",
    "    le = LabelEncoder()\n",
    "    encoded_labels = le.fit_transform(classification_labels)\n",
    "\n",
    "    # Train model\n",
    "    clf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf_model.fit(classification_features, encoded_labels)\n",
    "\n",
    "    return clf_model, le, feature_columns\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Load all data\n",
    "        classification_data, training_data, test_usernames, regression_test_data = load_and_preprocess_data()\n",
    "        \n",
    "        # === Classification Part ===\n",
    "        logger.info(\"Starting classification...\")\n",
    "        training_df = process_profile_data(training_data)\n",
    "        clf_model, le, feature_columns = train_classification_model(training_df, classification_data)\n",
    "        \n",
    "        if clf_model is not None:\n",
    "            classification_predictions = {}\n",
    "            test_df = training_df[training_df['username'].isin(test_usernames)]\n",
    "            \n",
    "            for _, row in test_df.iterrows():\n",
    "                features = pd.DataFrame([row[feature_columns]])\n",
    "                pred = clf_model.predict(features)[0]\n",
    "                classification_predictions[row['username']] = le.inverse_transform([pred])[0]\n",
    "\n",
    "            with open('classification_output.json', 'w') as f:\n",
    "                json.dump(classification_predictions, f, indent=4)\n",
    "\n",
    "        # === Regression Part ===\n",
    "        logger.info(\"Starting regression...\")\n",
    "        # Extract and prepare training data for regression\n",
    "        training_posts = extract_posts_data(training_data)\n",
    "        \n",
    "        if training_posts:\n",
    "            # Prepare features and train regression model\n",
    "            X_train, y_train, tfidf = prepare_regression_features(training_posts, is_training=True)\n",
    "            \n",
    "            reg_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            reg_model.fit(X_train, y_train)\n",
    "\n",
    "            # Prepare test features\n",
    "            X_test, _ = prepare_regression_features(regression_test_data, tfidf=tfidf, is_training=False)\n",
    "\n",
    "            # Generate predictions\n",
    "            regression_predictions = {}\n",
    "            for i, post in enumerate(regression_test_data):\n",
    "                pred = reg_model.predict(X_test.iloc[[i]])[0]\n",
    "                regression_predictions[post['id']] = int(max(0, round(pred)))  # Ensure non-negative integer predictions\n",
    "\n",
    "            with open('regression_output.json', 'w') as f:\n",
    "                json.dump(regression_predictions, f, indent=4)\n",
    "\n",
    "            logger.info(\"Completed both classification and regression predictions!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca054fd-5fe9-408f-a5d3-8542d2885288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
